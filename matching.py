import re
from collections import defaultdict
from os import path
from string import whitespace
from typing import List
from futils import timeit
import logging
import sbol2

from Bio import Seq, SeqIO, SeqRecord, pairwise2
from Bio.Align import PairwiseAligner
from time import time

def read_file(filename: str):
    """
    Read file and return content

    :param filename: Filename to read (string)
    :returns: file contents (string)

    """
    with open(filename, "r") as file_object:
        file_contents = file_object.read()
        return file_contents


def file_to_seqrec(f: str):
    """
    Read file return SeqRec

    :param filename: Filename to read and convert to SeqRec (string)

    :returns: SeqRecord

    """
    basename = path.basename(f)
    name = path.splitext(basename)[0]
    seq = Seq.Seq(read_file(f).strip(whitespace))  # strip newlines and shit
    seqrec = SeqRecord.SeqRecord(seq, id=name, name=name, description=name)
    return seqrec


def sbol_to_seqrec(f: str):
    """
    Read an SBOL file and return SeqRec 

    :param filename: Filename to read and convert to SeqRec (string)

    :returns: SeqRecord
    """
    basename = path.basename(f)
    name = path.splitext(basename)[0]
    doc = sbol2.Document()
    doc.read(f)
    # Here we assume the sbol has one element
    # TODO do this properly if doc has multiple elements (?)
    # TODO get name from SBOL document
    s = doc.sequences[0].elements.upper()
    seq = Seq.Seq(s)
    seqrec = SeqRecord.SeqRecord(seq, id=name, name=name, description=name)
    return seqrec


class Part:
    """
    Part class
    """

    def __init__(self, part: dict, part_type: str, repository: str):
        """
        Constructor from part dictionary (see template)
        """
        self.name = part["name"]
        self.filetype = part["filetype"]
        self.filename = part["filename"]
        self.type = part_type
        filepath = f"{repository}/parts/{self.type}/{self.filename}"
        if self.filetype == "genbank":
            self.sequence = SeqIO.read(filepath, self.filetype)
        elif self.filetype == "text":
            self.sequence = file_to_seqrec(filepath)
        elif self.filetype == "sbol":
            self.sequence = sbol_to_seqrec(filepath)
        else:
            raise ValueError(
                "Unrecognized filetype. Only Genbank and Text files are handled."
            )

    def __repr__(self):
        """
        Representation of the Part class
        """
        return f"{self.__class__.__name__}({self.name}, {self.type}, {self.filename}, {self.filetype})"


class Trace:
    """
    Trace class
    """

    def __init__(self, filename: str):
        """
        Constructor from trace filename
        """

        basename = path.basename(filename)
        self.name = basename.split(".")[0]
        self.filetype = basename.split(".")[1]
        self.filename = basename
        record = SeqIO.read(filename, "abi")
        self.record = record
        channels = [
            "DATA9",
            "DATA10",
            "DATA11",
            "DATA12",
            "PCON2",
            "SMPL1",
            "PBAS2",
            "PLOC1",
            "FWO_1",
        ]
        trace = defaultdict(list)
        for c in channels:
            trace[c] = record.annotations["abif_raw"][c]
        self.trace_binary = trace["PCON2"]
        self.trace_string = "".join([chr(value + 33) for value in trace["PCON2"]])
        self.phred_quality = record.letter_annotations["phred_quality"]
        self.sample = trace["SMPL1"].decode()  # Sample name
        self.sequence = trace["PBAS2"].decode()  # Sequence as generated by BaseCaller
        self.baseorder = tuple(trace["FWO_1"].decode())  # Base order
        # We assign the self.G, self.T, self.A, self.C attributes according to the base order from the ABIF file
        channelsorder = ("DATA9", "DATA10", "DATA11", "DATA12")
        exec(f"self.{self.baseorder[0]} = trace['{channelsorder[0]}']")
        exec(f"self.{self.baseorder[1]} = trace['{channelsorder[1]}']")
        exec(f"self.{self.baseorder[2]} = trace['{channelsorder[2]}']")
        exec(f"self.{self.baseorder[3]} = trace['{channelsorder[3]}']")
        self.ploc = trace["PLOC1"]  # Peak location array
        self.peak_G = [self.G[peak] for peak in self.ploc]
        self.peak_A = [self.A[peak] for peak in self.ploc]
        self.peak_T = [self.T[peak] for peak in self.ploc]
        self.peak_C = [self.C[peak] for peak in self.ploc]

    def compute_seq_from_trace(self):
        """
        Compute the sequence of the most probable nucleotides
        from the 4 channels from the trace file (the one with the strongest signal)
        for each peak location.
        """
        bases = []
        result = ""
        for i in range(len(self.ploc)):
            bases.append(
                (self.peak_G[i], self.peak_A[i], self.peak_T[i], self.peak_C[i])
            )
        for i in bases:
            m = max(i)
            pos = i.index(m)
            result += self.baseorder[pos]
        return result

    def compute_probability(self):
        """
        Compute probability of bases at pic location
        Return list of tuple of probability of bases
        Tuples are in baseorder
        """
        result = []
        peaks = {"G": self.peak_G, "A": self.peak_A, "T": self.peak_T, "C": self.peak_C}
        # method creating lists for each base first and then loooping to create the tuple
        if 0:
            lg, la, lt, lc, = (
                [],
                [],
                [],
                [],
            )
            tup = {"G": lg, "A": la, "T": lt, "C": lc}
            for i in range(len(self.ploc)):
                s = sum(
                    (self.peak_G[i], self.peak_A[i], self.peak_T[i], self.peak_C[i])
                )
                lg.append(self.peak_G[i] / s)
                la.append(self.peak_A[i] / s)
                lt.append(self.peak_T[i] / s)
                lc.append(self.peak_C[i] / s)
                ll = []
                for j in range(0, 4, 1):
                    b = self.baseorder[j]
                    ll.append(tup[b][i])
                l.append(tuple(ll))
        for i in range(len(self.ploc)):
            s = sum((self.peak_G[i], self.peak_A[i], self.peak_T[i], self.peak_C[i]))
            # method with looping over the base order to create the tuple
            if 0:
                ll = []
                # Return tuple in the order of the bases (self.baseorder)
                for j in range(0, 4, 1):
                    base = self.baseorder[j]
                    ll.append(peaks[base][i] / s if s else 0)
                l.append(tuple(ll))
            # method with direct tuple
            bases_prob = (
                peaks[self.baseorder[0]][i] / s,
                peaks[self.baseorder[1]][i] / s,
                peaks[self.baseorder[2]][i] / s,
                peaks[self.baseorder[3]][i] / s,
            )
            result.append(bases_prob)
        # return lg, la, lt, lc
        # return lg, la, lt, lc, l
        return result

    def compute_seq_from_probability(self):
        """
        Call compute probability from trace and return sequence string
        """
        result = self.compute_probability()
        seq = ""
        for t in result:
            idx = t.index(max(t))
            seq += self.baseorder[idx]
        return seq

    def __repr__(self):
        """
        Representation of the Trace object
        """
        return (
            f"{self.__class__.__name__}({self.name}, {self.filename}, {self.filetype})"
        )


class Sequence:
    """
    Sequence class
    """

    def __init__(self, filename: str, directionforward=True):
        """
        Constructor from sequence file
        """
        basename = path.basename(filename)
        self.dirname = path.dirname(filename)
        self.name = basename.split(".")[0]
        self.filetype = basename.split(".")[1]
        self.filename = basename
        # self.sequence = Seq.Seq( read_file(filename).strip(whitespace)).reverse_complement()  
        
        if self.filetype.lower() == "fastq" or self.filetype.lower() == "fasta":
           
            self.sequence = self._extract_fastq_sequence(filename, directionforward)
        else:
            
            if directionforward:
                self.sequence = Seq.Seq(read_file(filename).strip(whitespace))
            else:
                # self.sequence = Seq.Seq(read_file(filename).strip(whitespace)).reverse_complement()
                self.sequence = Seq.Seq(read_file(filename).strip(whitespace))[::-1] # For only reverse sequence

        
        # self.sequence = Seq.Seq(read_file(filename).strip(whitespace))
        # self.trace = self.get_trace()
        self.length = len(self.sequence)
        # breakpoint()
    def _extract_fastq_sequence(self, filename: str, directionforward) -> Seq.Seq:
        """
        Extracts sequence data from a FASTQ file. TODO: deal with multiple sequences
        """
        sequences = []
        with open(filename, "r") as file:
            for i, line in enumerate(file):
                if i == 1:  # TODO: Use % to loop through multiple sequences
                    sequences= line.strip() # Append to list for multiple seqs
                    # print(sequences)
        if directionforward:
            return Seq.Seq("".join(sequences)) # TODO: change this to create list of individual seqs maybe? Joining doesn't make sense here
        else:
            # return Seq.Seq("".join(sequences)).reverse_complement()
            return Seq.Seq("".join(sequences))[::-1]

    def __repr__(self):
        """
        Representation
        """
        return (
            f"{self.__class__.__name__}({self.name}, {self.filename}, {self.filetype})"
        )

    def count_n(self) -> int:
        """
        Count the number of N bases in the sequence
        """
        n = self.sequence.count("N")
        return n

    def normalized_n_score(self) -> float:
        """
        Return the normalized score of N bases counts in the sequence

        :returns: normalized score (float)
        """
        return self.count_n() / self.length if self.length else 0

    def count_max_n_cluster(self) -> int:
        """
        Return the largest number of N bases cluster in the sequence

        ex: given a sequence "NNNACGCANNNNANAANNNNNN"
            the function will return 6

        :returns: largest numver of N bases cluster (int)
        """
        seq = str(self.sequence)
        result = len(max(re.compile("(N+N)*").findall(seq)))  # Find maximum number of N
        return result

    def normalized_max_n_score(self) -> float:
        """
        Return the normalized score of the largest N bases cluster in the sequence

        :returns: normalized score (float)
        """
        return self.count_n() / self.length if self.length else 0

    def get_trace(self) -> Trace:
        """
        Return a Trace object associated to the sequence

        :returns: Trace object (Trace)
        """
        trace_file = path.join(self.dirname, self.name + ".ab1")
        if path.exists(trace_file):
            trace = Trace(trace_file)
        else:
            raise OSError("Trace file not found", trace_file)
        return trace


class Library:
    """
    Library class
    """

    def __init__(self, library_template: dict):
        """
        Constructur from library template
        """
        self.parts = []
        self.type = library_template["type"]
        self.name = library_template["name"]
        self.repository = library_template["repository"]
        for part in library_template["parts"]:
            # print('part:  ', part)
            self.parts.append(Part(part, self.type, self.repository))

    def __repr__(self):
        """
        Representation of the Library object
        """
        return f"{self.__class__.__name__}({self.name}, {self.type}, {self.parts})"


class PartCandidate:
    """
    PartCandidate class
    """

    def __init__(self, part):
        """
        Constructor from part dictionary (see template)
        """
        self.name = part[0]
        self.score = part[1]
        self.start = part[2]
        self.length = part[3]
        self.end = part[4]
        self.alignment = part[5]

    def __repr__(self):
        """
        Representation of the PartCandidate object
        """
        return f"{self.__class__.__name__}({self.name}, {self.score}, {self.start}, {self.length}, {self.end}, <alignments>)"


def score_pairwise(s1, s2, match=1, mismatch=-1, gap_open=-2, gap_extend=-1):
    score = 0
    in_gap1 = in_gap2 = False

    for c1, c2 in zip(s1, s2):
        if c1 == '-' or c2 == '-':
            if c1 == '-':
                if not in_gap1:
                    score += gap_open
                    in_gap1 = True
                else:
                    score += gap_extend
            if c2 == '-':
                if not in_gap2:
                    score += gap_open
                    in_gap2 = True
                else:
                    score += gap_extend
        else:
            in_gap1 = in_gap2 = False
            score += match if c1 == c2 else mismatch
    return score

@timeit
def match_part(
    sequence: Sequence, part: Part, threshold: float = 0.5, directionforward=True
) -> List[PartCandidate]:
    """
    Match part to a sequence and return candidates that score above the threshold

    :param sequence: Sequence object
    :param part: Library object
    :param threshold:  (Default value = 0.5)

    """
    logging.info(part.name)
    candidates = []
    if directionforward:
        part_rc = part.sequence.seq
    else:
        # part_rc = part.sequence.seq.reverse_complement() # For 35 direction
        part_rc = part.sequence.seq[::-1] # For reverse sequences, not 35 direction

    start = time()
    alignments_forward = pairwise2.align.localms(part_rc, sequence.sequence, 1, -1, -2, -1)
    
    alignments_reverse = pairwise2.align.localms(part_rc[::-1], sequence.sequence[::-1], 1, -1, -2, -1)
    # breakpoint()
    
    if not alignments_forward or not alignments_reverse:
        return candidates  
    
    if len(alignments_forward) != len(alignments_reverse):
        print(f"Warning: Mismatched alignment counts - forward: {len(alignments_forward)}, reverse: {len(alignments_reverse)}")
        # Use the shorter length to avoid index errors
        iterations = min(len(alignments_forward), len(alignments_reverse))
    else:
        iterations = len(alignments_forward)
    
    
    seen_positions = set()  
    
    for i in range(iterations):
        fwd_alignment = alignments_forward[i]
        rev_alignment = alignments_reverse[i]
        
        # Extract region of interest from sequence.sequence 
        # Part start = start position from the forward align
        # Part end = sequence length - start position of reverse align 
        start_pos = fwd_alignment.start
        end_pos = len(sequence.sequence) - rev_alignment.start
        target_subseq = sequence.sequence[start_pos:end_pos]


        
        # Skip duplicates based on position
        position_key = (start_pos, end_pos)
        if position_key in seen_positions:
            continue
        
        seen_positions.add(position_key)
        # # Align the extracted region to part reference
        realignments = pairwise2.align.localms(part_rc, target_subseq, 1, -1, -2, -1)

        if not realignments:
            continue  

        # Use best alignment (first one)
        realign = realignments[0]
        aligned_part, aligned_target, raw_score, _, _ = realign

        # Manually re-score the alignment for just the selected region target.
        # Avoids the pairwise score which may be influenced by spurious start/end positions
        manual_score = score_pairwise(aligned_part, aligned_target, match=1, mismatch=-1, gap_open=-2, gap_extend=-1)

        # end = time()
        # print(len(alignments_forward), end-start)
        # Normalize score by part length
        normalized_score = manual_score / len(part.sequence.seq) if raw_score!=manual_score else raw_score/len(part.sequence.seq)
                
        if normalized_score > threshold:
            candidate = (
                part.name,
                normalized_score,
                start_pos,
                len(part.sequence.seq),
                end_pos,
                fwd_alignment,  
            )
            part_candidate = PartCandidate(candidate)
            candidates.append(part_candidate)
    return candidates




def score_part_against_ground_truth(
    sequence: Sequence, 
    part: Part, 
    ground_truth_start: int, 
    ground_truth_end: int, 
    threshold: float = 0.5,
    directionforward: bool = True 
) -> List[PartCandidate]:
    """
    Score how well a part matches a specific region within a sequence, defined by ground truth positions.
    This function skips the initial forward/reverse alignment inference and directly uses
    the provided ground_truth_start and ground_truth_end to define the target subsequence.

    :param sequence: Sequence object containing the full sequence.
    :param part: Part object representing the genetic part to match.
    :param ground_truth_start: The 0-based start position of the ground truth region in the sequence.
    :param ground_truth_end: The 0-based end position (exclusive) of the ground truth region in the sequence.
    :param threshold: Normalized score threshold for a candidate to be considered valid (Default: 0.5).
    :param directionforward: Boolean indicating if the part sequence is forward or should be reversed for alignment.
                             (Default: True)

    Returns:
        List[PartCandidate]: A list of PartCandidate objects if the match meets the threshold.
                             Typically, only one candidate is expected per ground truth region.
    """
    logging.info(f"Scoring {part.name} against ground truth region [{ground_truth_start}-{ground_truth_end}] in {sequence.uid if hasattr(sequence, 'uid') else 'sequence'}")
    
    candidates = []

    
    if directionforward:
        part_seq_for_alignment = part.sequence.seq
    else:
        part_seq_for_alignment = part.sequence.seq[::-1] 

    if not (0 <= ground_truth_start < ground_truth_end <= len(sequence.sequence)):
        logging.warning(f"Invalid ground truth positions: [{ground_truth_start}-{ground_truth_end}] for sequence length {len(sequence.sequence)}. Skipping.")
        return []

    target_subseq = sequence.sequence[ground_truth_start:ground_truth_end]
    if not target_subseq:
        logging.info(f"Target subsequence too short or empty for {part.name} at [{ground_truth_start}-{ground_truth_end}]. Skipping.")
        return []

    
    alignments = pairwise2.align.localms(part_seq_for_alignment, target_subseq, 1, -1, -2, -1)

    if not alignments:
        logging.info(f"No alignment found for {part.name} against ground truth region [{ground_truth_start}-{ground_truth_end}].")
        return []

    # Use the best alignment (usually the first one)
    best_realign = alignments[0]
    aligned_part, aligned_target, raw_score, _, _ = best_realign

    # Manually re-score the alignment for just the selected region target.
    # This ensures the score is based solely on the match within the ground truth window.
    manual_score = score_pairwise(aligned_part, aligned_target, match=1, mismatch=-1, gap_open=-2, gap_extend=-1)
    part_original_length = len(part.sequence.seq)
    if part_original_length == 0:
        logging.warning(f"Part '{part.name}' has zero length. Cannot normalize score.")
        return []
    normalized_score = manual_score / part_original_length
            
    if normalized_score > threshold:
        
        candidate = (
            part.name,
            normalized_score,
            ground_truth_start, 
            part_original_length, 
            ground_truth_end,   
            None, 
        )
        part_candidate = PartCandidate(candidate)
        candidates.append(part_candidate)
        
    return candidates


def match_part_probability_trace(
    sequence: Sequence, part: Part, threshold: float = 0.5
) -> List[PartCandidate]:
    """
    Match part to the computed probability sequence of a sequence (from trace file) and return candidates that score above the threshold

    :param sequence: Sequence object
    :param part: Library object
    :param threshold:  (Default value = 0.5)

    """
    candidates = []
    # Calculate Alignments
    part_rc = part.sequence.seq.reverse_complement()
    # Compute probability sequence from Trace
    seq_prob = sequence.trace.compute_seq_from_probability()
    seq = Seq.Seq(seq_prob)
    # Align
    alignments = pairwise2.align.localms(part_rc, seq, 1, -1, -2, -1)
    for alignment in alignments:
        score = alignment.score / len(part.sequence.seq)  # normalize score
        if score > threshold:
            candidate = (
                part.name,
                score,
                alignment.start,
                len(part.sequence.seq),
                alignment.end,
                alignment,
            )
            part_candidate = PartCandidate(candidate)
            candidates.append(part_candidate)
    return candidates


def match_library(
    sequence: Sequence, library: Library, gt_positions:dict = None, threshold: float = 0.1, directionforward=True
) -> List[PartCandidate]:
    """
    Match library of parts to a sequence and return candidates that score above the threshold.

    :param sequence: Sequence object
    :param library: Library object
    :param gt_positions: Dict of ground truth positions for each part used to evaluate scoring on simulated sequences. 
    :param threshold:  (Default value = 0.5)
    :param directionforward: Bool defining whether to match in forward or reverse direction (not reverse complement)

    """
    library_candidates = []
    for part in library.parts:
        # print('Library part: ', part)
        if gt_positions:
            start = gt_positions["_".join(sequence.name.split("_")[:5])][part.name][0]
            end = gt_positions["_".join(sequence.name.split("_")[:5])][part.name][1]                                            
            part_candidates = score_part_against_ground_truth(sequence, part,start, end, threshold, directionforward)
        else:
            part_candidates = match_part(sequence, part, threshold, directionforward)
        
        if part_candidates:
            library_candidates.append(part_candidates)
    return library_candidates


def match_library_proba(
    sequence: Sequence, library: Library, threshold: float = 0.1
) -> List[PartCandidate]:
    """
    Match library of parts to a sequence and return candidates that score above the threshold.

    :param sequence: Sequence object
    :param library: Library object
    :param threshold:  (Default value = 0.5)

    """
    library_candidates = []
    for part in library.parts:
        part_candidates = match_part_probability_trace(sequence, part, threshold)
        if part_candidates:
            library_candidates.append(part_candidates)
    return library_candidates


def get_score(part: Part) -> float:
    """
    Get score function (used to order the get_top_score() results)
    see function below.
    """
    return part.score


def get_top_scores(partcandidates_list: List[PartCandidate]) -> PartCandidate:
    """
    Get top scores

    :param partcandidates_list: List of PartCandidates

    """
    result = sorted(partcandidates_list, key=get_score)
    top = result[0]
    return top
